{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be383c87-0778-458c-9cee-1a44926452cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## HST ACS-WFC Dataset Preparation\n",
    "\n",
    "In this notebook, we prepare the **HST ACS-WFC Cosmic Ray dataset**.\n",
    "\n",
    "1. **Download and Extract Data**  \n",
    "   The training and test datasets are downloaded from Zenodo (https://zenodo.org/record/4295902) as compressed tar archives and extracted into a base directory.  \n",
    "   The extracted data are organized into separate training and test folders.\n",
    "\n",
    "2. **Dataset Organization**  \n",
    "   After extraction, the data are stored as NumPy files (`.npy`) organized hierarchically by:\n",
    "   - filter\n",
    "   - proposal ID\n",
    "   - visit number  \n",
    "\n",
    "   Each directory contains image patches, corresponding CR masks, and auxiliary files (e.g., `sky.npy`).\n",
    "\n",
    "3. **Collect Training and Test File Paths**  \n",
    "   We recursively traverse the directory structure to gather all valid `.npy` files (excluding sky background files) for:\n",
    "   - the training set\n",
    "   - the test set  \n",
    "\n",
    "4. **Save File Lists**  \n",
    "   The collected file paths are saved as:\n",
    "   - `train_dirs.npy`\n",
    "   - `test_dirs.npy`  \n",
    "\n",
    "   These files provide a convenient index for loading the HST data during training and evaluation.\n",
    "\n",
    "After this step, the HST ACS-WFC dataset is fully indexed and ready to be used with CRNet or deepCR-style PyTorch data pipelines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74733f5e-3275-4c09-9dc9-87375fc0b7ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Downloading training data\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "Downloading test data\n",
      "------------------------------------------------------------\n",
      "Datasets downloaded\n",
      "Sorting...\n",
      "Complete\n",
      "Extracting tar files...\n",
      "Complete\n",
      "------------------------------------------------------------\n",
      "Fetching directories for the test set\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "Fetching directories for the training set\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import shutil\n",
    "import tarfile\n",
    "import urllib\n",
    "%matplotlib inline\n",
    "\n",
    "# Base directory setup\n",
    "# os.makedirs('/scratch/srinadb/CRNet/CRNet/deepCR.ACS-WFC')\n",
    "base_dir = os.path.join('/scratch/srinadb/CRNet/CRNet/deepCR.ACS-WFC')\n",
    "# os.makedirs(os.path.join(base_dir,'data'))\n",
    "data_base = os.path.join(base_dir,'data')\n",
    "\n",
    "def download():\n",
    "    #Download training data\n",
    "    print('------------------------------------------------------------')\n",
    "    print('Downloading training data')\n",
    "    print('------------------------------------------------------------')\n",
    "    # urllib.request.urlretrieve('https://zenodo.org/record/4295902/files/deepCR.ACS-WFC.train.tar?download=1')\n",
    "    \n",
    "    #Donwload test data\n",
    "    print('------------------------------------------------------------')\n",
    "    print('Downloading test data')\n",
    "    print('------------------------------------------------------------')\n",
    "    # urllib.request.urlretrieve('https://zenodo.org/record/4295902/files/deepCR.ACS-WFC.test.tar?download=1')\n",
    "    \n",
    "    print('Datasets downloaded')\n",
    "    print('Sorting...')\n",
    "    # shutil.move('deepCR.ACS-WFC.train.tar',data_base)\n",
    "    # shutil.move('deepCR.ACS-WFC.test.tar',data_base)\n",
    "    print('Complete')\n",
    "    \n",
    "    print('Extracting tar files...')\n",
    "    # train_tar = tarfile.open(os.path.join(data_base,'deepCR.ACS-WFC.train.tar'))\n",
    "    # test_tar = tarfile.open(os.path.join(data_base,'deepCR.ACS-WFC.test.tar'))\n",
    "    \n",
    "    # train_tar.extractall(data_base)\n",
    "    # test_tar.extractall(data_base)\n",
    "    print('Complete')\n",
    "    \n",
    "    return None\n",
    "\n",
    "#Directories\n",
    "def get_dirs():\n",
    "    train_dirs = []\n",
    "    test_dirs = []\n",
    "\n",
    "    test_base = os.path.join(data_base,'npy_test')\n",
    "    train_base = os.path.join(data_base,'npy_train')\n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    print('Fetching directories for the test set')\n",
    "    print('------------------------------------------------------------')\n",
    "    for _filter in os.listdir(test_base):\n",
    "        filter_dir = os.path.join(test_base,_filter)\n",
    "        if os.path.isdir(filter_dir):\n",
    "            for prop_id in os.listdir(filter_dir):\n",
    "                prop_id_dir = os.path.join(filter_dir,prop_id)\n",
    "                if os.path.isdir(prop_id_dir):\n",
    "                    for vis_num in os.listdir(prop_id_dir):\n",
    "                        vis_num_dir = os.path.join(prop_id_dir,vis_num)\n",
    "                        if os.path.isdir(vis_num_dir):\n",
    "                            for f in os.listdir(vis_num_dir):\n",
    "                                if '.npy' in f and f != 'sky.npy':\n",
    "                                    test_dirs.append(os.path.join(vis_num_dir,f))\n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    print('Fetching directories for the training set')\n",
    "    print('------------------------------------------------------------')\n",
    "    for _filter in os.listdir(train_base):\n",
    "        filter_dir = os.path.join(train_base,_filter)\n",
    "        if os.path.isdir(filter_dir):\n",
    "            for prop_id in os.listdir(filter_dir):\n",
    "                prop_id_dir = os.path.join(filter_dir,prop_id)\n",
    "                if os.path.isdir(prop_id_dir):\n",
    "                    for vis_num in os.listdir(prop_id_dir):\n",
    "                        vis_num_dir = os.path.join(prop_id_dir,vis_num)\n",
    "                        if os.path.isdir(vis_num_dir):\n",
    "                            for f in os.listdir(vis_num_dir):\n",
    "                                if '.npy' in f and f != 'sky.npy':\n",
    "                                    train_dirs.append(os.path.join(vis_num_dir,f))\n",
    "#     print(train_dirs)\n",
    "    np.save(os.path.join(base_dir,'test_dirs.npy'), test_dirs)\n",
    "    np.save(os.path.join(base_dir,'train_dirs.npy'), train_dirs)\n",
    "\n",
    "    return None\n",
    "\n",
    "download()\n",
    "get_dirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a63a489-a4ee-4e54-b859-64c183beb82c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "srinadh_astro",
   "language": "python",
   "name": "srinadh_astro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
